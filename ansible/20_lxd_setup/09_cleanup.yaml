---
# 09_cleanup.yaml - Clean up container-based deployment artifacts (rollback)
# Run with: ansible-playbook -i inventory/inventory.yaml ansible/20_lxd_setup/09_cleanup.yaml

- name: Clean up container-based deployment artifacts
  hosts: baremetal
  become: true
  gather_facts: true
  
  vars:
    # All possible container and VM names we might have created
    instance_names:
      - "tkc"      # Control plane
      - "tkw1"     # Worker 1
      - "tkw2"     # Worker 2
      - "dns1"     # DNS server
      - "k8s-control"    # Alternative control name
      - "k8s-worker"     # Alternative worker name
      - "k8s-worker-1"   # Alternative worker name
      - "k8s-worker-2"   # Alternative worker name
      - "k8s-dns"        # Alternative DNS name
      - "microk8s-control" # Yet another naming scheme
      - "microk8s-worker-1"
      - "microk8s-worker-2"
      
    # All LXD profiles we might have created
    lxd_profiles:
      # Container-based profiles
      - "control-node"
      - "worker-node"
      - "dns-server"
      - "microk8s"
      # VM-based profiles
      - "vm-networks"
      - "vm-resources"
      - "vm-gpu"
      - "microk8s-vm"
      - "k8s-vm"
      - "gpu-passthrough"
      - "default-vm"
      - "vm-profile"
      
    # Fixed DNS IP address to avoid template loops
    fixed_dns_ip: "192.168.191.1"
  
  tasks:
    - name: Display cleanup warning
      ansible.builtin.debug:
        msg: |
          ════════════════════════════════════════════════════════════════════════
          ⚠️  WARNING: CLEAN UP OPERATION  ⚠️
          ════════════════════════════════════════════════════════════════════════
          
          This playbook will remove all containers, VMs, and related resources from:
            - {{ inventory_hostname }}
          
          All data will be permanently deleted. This action cannot be undone.
          
          If you want to continue, press ENTER when prompted.
          To abort, press Ctrl+C.
          
          ════════════════════════════════════════════════════════════════════════
    
    - name: Confirm cleanup operation
      ansible.builtin.pause:
        prompt: "Press ENTER to continue with cleanup, or Ctrl+C to abort"
      
    # Phase 1: Stop and remove all existing containers and VMs
    - name: Check existing containers and VMs
      ansible.builtin.command: lxc list --format json
      register: lxc_list_json
      changed_when: false
      
    - name: Parse existing instances
      ansible.builtin.set_fact:
        existing_instances: "{{ (lxc_list_json.stdout | from_json | map(attribute='name') | list) }}"
      
    - name: Display existing containers and VMs
      ansible.builtin.debug:
        msg: |
          Existing containers and VMs on {{ inventory_hostname }}:
          
          {% for instance in existing_instances %}
          - {{ instance }}
          {% else %}
          No instances found.
          {% endfor %}
    
    # First stop all instances (named + any others found)
    - name: Stop all named containers and VMs
      ansible.builtin.command: lxc stop {{ item }} --force
      loop: "{{ instance_names }}"
      register: stop_named_result
      failed_when: stop_named_result.rc != 0 and "not found" not in stop_named_result.stderr and "already stopped" not in stop_named_result.stderr
      changed_when: stop_named_result.rc == 0
      
    - name: Stop all existing containers and VMs
      ansible.builtin.command: lxc stop {{ item }} --force
      loop: "{{ existing_instances }}"
      register: stop_all_result
      failed_when: stop_all_result.rc != 0 and "not found" not in stop_all_result.stderr and "already stopped" not in stop_all_result.stderr
      changed_when: stop_all_result.rc == 0
      
    # Then delete all instances (named + any others found)  
    - name: Delete all named containers and VMs
      ansible.builtin.command: lxc delete {{ item }}
      loop: "{{ instance_names }}"
      register: delete_named_result
      failed_when: delete_named_result.rc != 0 and "not found" not in delete_named_result.stderr
      changed_when: delete_named_result.rc == 0
      
    - name: Delete all existing containers and VMs
      ansible.builtin.command: lxc delete {{ item }}
      loop: "{{ existing_instances }}"
      register: delete_all_result
      failed_when: delete_all_result.rc != 0 and "not found" not in delete_all_result.stderr
      changed_when: delete_all_result.rc == 0
      
    # Phase 2: Clean up LXD profiles
    - name: List LXD profiles
      ansible.builtin.command: lxc profile list
      register: profile_list
      changed_when: false
      
    - name: Display existing LXD profiles
      ansible.builtin.debug:
        msg: |
          Existing LXD profiles on {{ inventory_hostname }}:
          
          {{ profile_list.stdout }}
    
    - name: Delete LXD profiles
      ansible.builtin.command: lxc profile delete {{ item }}
      loop: "{{ lxd_profiles }}"
      register: profile_delete
      failed_when: profile_delete.rc != 0 and "not found" not in profile_delete.stderr
      changed_when: profile_delete.rc == 0
      
    # Phase 3: Clean up network routes
    - name: Remove Kubernetes API routes
      ansible.builtin.shell: |
        # Remove any routes to Kubernetes API subnet
        if ip route | grep -q "10.152.183.0/24"; then
          ip route del 10.152.183.0/24
          echo "Kubernetes API route removed"
        else
          echo "No Kubernetes API route found"
        fi
      register: route_cleanup
      changed_when: "'Kubernetes API route removed' in route_cleanup.stdout"
      
    # Phase 4: Clean up host entries
    - name: Remove container/VM entries from /etc/hosts
      ansible.builtin.lineinfile:
        path: /etc/hosts
        regexp: "{{ item }}\\."
        state: absent
      loop: "{{ instance_names }}"
      
    # Phase 5: Clean up firewall rules
    - name: Clean up iptables rules for containers/VMs
      ansible.builtin.shell: |
        # Remove any container-specific rules
        iptables-save | grep -v "{{ item }}" | iptables-restore
      loop: "{{ instance_names }}"
      changed_when: false
      
    # Phase 6: Clean up LXD storage volumes
    - name: Check existing LXD storage volumes
      ansible.builtin.command: lxc storage volume list default --format json
      register: storage_volumes_json
      changed_when: false
      failed_when: false
      
    - name: Parse storage volumes
      ansible.builtin.set_fact:
        storage_volumes: "{{ (storage_volumes_json.stdout | default('[]') | from_json | map(attribute='name') | list) }}"
      when: storage_volumes_json.rc == 0
      
    - name: Display storage volumes
      ansible.builtin.debug:
        msg: |
          LXD storage volumes on {{ inventory_hostname }}:
          
          {% for volume in storage_volumes | default([]) %}
          - {{ volume }}
          {% else %}
          No storage volumes found.
          {% endfor %}
      when: storage_volumes is defined
    
    - name: Delete VM-related storage volumes
      ansible.builtin.command: lxc storage volume delete default {{ item }}
      loop: "{{ storage_volumes | default([]) }}"
      register: volume_delete
      failed_when: volume_delete.rc != 0 and "not found" not in volume_delete.stderr
      changed_when: volume_delete.rc == 0
      when: storage_volumes is defined and (item in instance_names or 'vm-' in item or 'microk8s' in item or 'k8s' in item)

    # Phase 7: Comprehensive network cleanup
    - name: Clean up Kubernetes and ZeroTier routes
      ansible.builtin.shell: |
        echo "Cleaning up network routes..."
        
        # Remove Kubernetes API routes
        if ip route | grep -q "10.152.183.0/24"; then
          ip route del 10.152.183.0/24
          echo "Kubernetes API route removed"
        fi
        
        # Remove ZeroTier network routes
        if ip route | grep -q "192.168.191.0/24"; then
          ip route del 192.168.191.0/24
          echo "ZeroTier network route removed"
        fi
        
        # Remove any other Kubernetes subnet routes
        if ip route | grep -q "10.1.0.0/16"; then
          ip route del 10.1.0.0/16
          echo "Kubernetes pod network route removed"
        fi
        
        # Remove specific cluster IP routes
        for route in $(ip route | grep "192.168.19" | cut -d ' ' -f 1); do
          ip route del $route
          echo "Removed route: $route"
        done
        
        # Clean up iptables rules
        echo "Cleaning up iptables rules..."
        
        # Backup current rules
        iptables-save > /tmp/iptables-backup.rules
        
        # Remove rules related to containers, VMs, and networking
        cat /tmp/iptables-backup.rules | grep -v "zt" | grep -v "lxdbr0" | grep -v "cni" | grep -v "flannel" | grep -v "KUBE" | grep -v "docker" | grep -v "calico" > /tmp/iptables-clean.rules
        
        # Restore cleaned rules
        iptables-restore < /tmp/iptables-clean.rules
        
        # Clean up backup files
        rm -f /tmp/iptables-backup.rules /tmp/iptables-clean.rules
        
        echo "Network rules cleanup completed"
      register: network_cleanup
      changed_when: "'removed' in network_cleanup.stdout"
      failed_when: false
      
    - name: Reset network namespace isolation
      ansible.builtin.shell: |
        echo "Cleaning up network namespace isolation..."
        
        # Check if any network namespaces exist
        if ip netns list | grep -q "."; then
          # For each namespace, delete it
          for ns in $(ip netns list); do
            ip netns delete $ns
            echo "Deleted network namespace: $ns"
          done
        else
          echo "No network namespaces found"
        fi
        
        # Reset sysctl network parameters
        echo "Resetting sysctl network parameters..."
        
        # Reset IP forwarding
        sysctl -w net.ipv4.ip_forward=0
        
        # Reset bridge-nf parameters
        sysctl -w net.bridge.bridge-nf-call-iptables=0
        sysctl -w net.bridge.bridge-nf-call-ip6tables=0
        
        echo "Network namespace and sysctl cleanup completed"
      register: netns_cleanup
      changed_when: "'Deleted' in netns_cleanup.stdout"
      failed_when: false
      
    - name: Check existing network bridges
      ansible.builtin.command: ip link show type bridge
      register: bridge_check
      changed_when: false
      failed_when: false
      
    - name: Display network bridges
      ansible.builtin.debug:
        msg: |
          Network bridges on {{ inventory_hostname }}:
          
          {{ bridge_check.stdout }}
    
    - name: Check lxdbr0 bridge status
      ansible.builtin.command: ip link show lxdbr0
      register: lxdbr0_status
      changed_when: false
      failed_when: false
    
    - name: Reset lxdbr0 bridge configuration
      ansible.builtin.command: "{{ item }}"
      loop:
        - lxc network set lxdbr0 ipv4.address=192.168.100.1/24
        - lxc network set lxdbr0 ipv4.nat=true
        - lxc network set lxdbr0 ipv4.dhcp=false
      when: lxdbr0_status.rc == 0
      changed_when: true
      register: reset_lxdbr0
      failed_when: false
      
    - name: Display lxdbr0 reset status
      ansible.builtin.debug:
        msg: "Reset lxdbr0 configuration: {{ 'Success' if reset_lxdbr0.changed else 'Not needed or failed' }}"
      when: lxdbr0_status.rc == 0
      
    - name: Check br0 bridge status
      ansible.builtin.command: ip link show br0
      register: br0_status
      changed_when: false
      failed_when: false
      
    - name: Display br0 bridge status
      ansible.builtin.debug:
        msg: "{{ 'br0 bridge is present and will be preserved' if br0_status.rc == 0 else 'WARNING: br0 bridge is missing - required for VM external connectivity' }}"
        
    - name: Show br0 details if present
      ansible.builtin.command: ip addr show br0
      register: br0_details
      changed_when: false
      failed_when: false
      when: br0_status.rc == 0
      
    - name: Display br0 details
      ansible.builtin.debug:
        msg: "{{ br0_details.stdout }}"
      when: br0_status.rc == 0 and br0_details.stdout is defined
      
    - name: Get list of other bridges
      ansible.builtin.shell: ip link show type bridge | grep -v "lxdbr0" | grep -v "br0" | grep "br" | cut -d ' ' -f 2 | tr -d ':'
      register: other_bridges
      changed_when: false
      failed_when: false
      
    - name: Clean up other bridges
      ansible.builtin.shell: |
        ip link set {{ item }} down
        ip link delete {{ item }}
        echo "Removed bridge: {{ item }}"
      loop: "{{ other_bridges.stdout_lines | default([]) }}"
      when: item != "lxdbr0" and item != "br0" and item.startswith("br")
      changed_when: true
      failed_when: false
      register: bridge_cleanup_details
    
    - name: Check ZeroTier status
      ansible.builtin.command: zerotier-cli info
      register: zerotier_info
      changed_when: false
      failed_when: false
    
    - name: Reset ZeroTier if installed
      ansible.builtin.shell: |
        if command -v zerotier-cli &> /dev/null; then
          echo "Resetting ZeroTier configuration..."
          
          # Get current networks
          NETWORKS=$(zerotier-cli listnetworks | tail -n +2 | awk '{print $3}')
          
          # Leave all networks
          for network in $NETWORKS; do
            zerotier-cli leave $network
            echo "Left ZeroTier network: $network"
          done
          
          # Restart ZeroTier service
          systemctl restart zerotier-one
          
          echo "ZeroTier reset completed"
        else
          echo "ZeroTier not installed, skipping reset"
        fi
      register: zerotier_reset
      changed_when: "'Left ZeroTier network' in zerotier_reset.stdout"
      failed_when: false
      when: zerotier_info.rc == 0
      
    - name: Restart networking to apply changes (if needed)
      ansible.builtin.service:
        name: "{{ item }}"
        state: restarted
      loop:
        - systemd-networkd
        - NetworkManager
      failed_when: false
      when: reset_lxdbr0.changed | default(false) or bridge_cleanup_details.changed | default(false) or network_cleanup is changed or netns_cleanup is changed or zerotier_reset is changed

    # Phase 8: Final verification
    - name: Verify containers and VMs are removed
      ansible.builtin.command: lxc list
      register: final_lxc_list
      changed_when: false
      
    - name: Verify profiles are removed
      ansible.builtin.command: lxc profile list
      register: final_profile_list
      changed_when: false
      
    - name: Verify storage volumes are removed
      ansible.builtin.command: lxc storage volume list default
      register: final_storage_list
      changed_when: false
      failed_when: false
      
    - name: Check final network status
      ansible.builtin.shell: |
        echo "=== Network Routes ==="
        ip route
        echo
        echo "=== Network Bridges ==="
        ip link show type bridge
        echo
        echo "=== ZeroTier Status ==="
        if command -v zerotier-cli &> /dev/null; then
          zerotier-cli info
          zerotier-cli listnetworks
        else
          echo "ZeroTier not installed"
        fi
      register: final_network_status
      changed_when: false
      failed_when: false
      
    - name: Display final state
      ansible.builtin.debug:
        msg: |
          ════════════════════════════════════════════════════════════════════════
          ✅ CLEANUP COMPLETED
          ════════════════════════════════════════════════════════════════════════
          
          REMAINING LXD INSTANCES:
          {{ final_lxc_list.stdout }}
          
          REMAINING LXD PROFILES:
          {{ final_profile_list.stdout }}
          
          {% if final_storage_list.rc == 0 %}
          REMAINING STORAGE VOLUMES:
          {{ final_storage_list.stdout }}
          {% endif %}
          
          NETWORK STATUS:
          {{ final_network_status.stdout }}
          
          VERIFICATION SUMMARY:
          - LXD instances: {% if final_lxc_list.stdout | trim | length == 0 %}✅ All removed{% else %}⚠️ Some instances remain{% endif %}
          - LXD profiles: {% if "default" in final_profile_list.stdout and final_profile_list.stdout.count('\n') <= 2 %}✅ Only default profile remains{% else %}⚠️ Custom profiles remain{% endif %}
          - Network bridges: {% if "lxdbr0" in final_network_status.stdout and "br0" in final_network_status.stdout %}✅ Required bridges present{% else %}⚠️ Bridge configuration issue{% endif %}
          
          The system is now ready for a clean VM-based deployment.
          
          Next steps:
            Run the VM profile setup playbook:
            ansible-playbook -i inventory/inventory.yaml ansible/20_lxd_setup/10_setup_lxd_cluster.yaml
          
          ════════════════════════════════════════════════════════════════════════