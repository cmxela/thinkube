---
# 20_create_microk8s_vms.yaml - Create LXD VMs for MicroK8s deployment
# Run with: ansible-playbook -i inventory/inventory.yaml ansible/vm_deployment/20_create_microk8s_vms.yaml

- name: Create LXD VMs for MicroK8s
  hosts: baremetal
  become: false
  gather_facts: true
  
  vars:
    vm_image: "ubuntu:24.04"
    vm_networks_profile: "vm-networks"
    vm_resources_profile: "vm-resources"
    vm_gpu_profile: "vm-gpu"
    network_gateway: "192.168.1.1"  # From inventory all.vars.network_gateway
    # Using fixed DNS IP to avoid template recursion issues
    fixed_dns_ip: "192.168.191.1"
    is_clustered: false  # Will be determined during execution
  
  tasks:
    # Phase 0: Check if LXD is in a cluster
    - name: Check if LXD is in a cluster - standard method
      ansible.builtin.command: lxc cluster list
      register: cluster_check
      changed_when: false
      failed_when: false
      become: true
      delegate_to: "{{ groups['baremetal'][0] }}"
      run_once: true
      
    # Alternative method to check cluster status
    - name: Check LXD info for cluster details
      ansible.builtin.command: lxc info
      register: lxd_info
      changed_when: false
      failed_when: false
      become: true
      delegate_to: "{{ groups['baremetal'][0] }}"
      run_once: true
      
    - name: Set is_clustered fact based on comprehensive detection
      ansible.builtin.set_fact:
        is_clustered: >-
          {{ 
            (cluster_check.rc == 0 and ('ONLINE' in cluster_check.stdout)) or 
            (lxd_info.rc == 0 and ('cluster:' in lxd_info.stdout or 'member_of:' in lxd_info.stdout)) 
          }}
      delegate_to: "{{ groups['baremetal'][0] }}"
      run_once: true
      
    - name: Display cluster status
      ansible.builtin.debug:
        msg: |
          ════════════════════════════════════════════════════════
          LXD CLUSTER STATUS
          ════════════════════════════════════════════════════════
          LXD is in a cluster: {{ is_clustered }}
          
          To run on cluster node:
          {% if is_clustered %}
          Use --target with lxc launch commands
          {% else %}
          Run directly on node hosting the VM
          {% endif %}
          ════════════════════════════════════════════════════════
      delegate_to: "{{ groups['baremetal'][0] }}"
      run_once: true
      
    # Phase 1: Verify LXD profiles exist
    - name: Verify that LXD profiles exist
      block:
        - name: Check if vm-networks profile exists
          ansible.builtin.command: lxc profile show {{ vm_networks_profile }}
          register: vm_networks_check
          changed_when: false
          failed_when: vm_networks_check.rc != 0
          become: true
          
        - name: Check if vm-resources profile exists
          ansible.builtin.command: lxc profile show {{ vm_resources_profile }}
          register: vm_resources_check
          changed_when: false
          failed_when: vm_resources_check.rc != 0
          become: true
          
        - name: Verify LXD storage pool
          ansible.builtin.command: lxc storage show default
          register: storage_check
          changed_when: false
          failed_when: storage_check.rc != 0
          become: true
      tags: verify_profiles
    
    # Phase 2: Create VMs
    - name: Create MicroK8s VMs
      block:
        # Get list of existing VMs in the cluster
        - name: Get list of existing VMs in the cluster
          ansible.builtin.command: lxc list
          register: vm_list
          changed_when: false
          become: true
          delegate_to: "{{ groups['baremetal'][0] }}"
          run_once: true
          
        # Create control plane VMs - only run on one host with proper target parameter
        - name: Create control plane VMs
          ansible.builtin.command: >
            lxc launch {{ vm_image }} {{ item }} --vm 
            --profile {{ vm_networks_profile }}
            --profile {{ vm_resources_profile }}
            {% if hostvars[item]['gpu_passthrough'] %}--profile {{ vm_gpu_profile }}{% endif %}
            --storage default
            {% if is_clustered | default(false) %}--target {{ hostvars[item]['parent_host'] }}{% endif %}
          register: control_vm_create
          failed_when: >
            control_vm_create.rc != 0 and 
            "already exists" not in control_vm_create.stderr and 
            "busy running" not in control_vm_create.stderr
          changed_when: "'already exists' not in control_vm_create.stderr"
          loop: "{{ groups['microk8s_control_plane'] }}"
          when:
            - "'microk8s_control_plane' in groups"
            - item not in vm_list.stdout
            - ((is_clustered | default(false)) and (inventory_hostname == groups['baremetal'][0])) or (not is_clustered and (inventory_hostname == hostvars[item]['parent_host']))
          become: true
          run_once: "{{ is_clustered | default(false) }}"
            
        # Create worker VMs - only run on one host with proper target parameter
        - name: Create worker VMs
          ansible.builtin.command: >
            lxc launch {{ vm_image }} {{ item }} --vm 
            --profile {{ vm_networks_profile }}
            --profile {{ vm_resources_profile }}
            {% if hostvars[item]['gpu_passthrough'] %}--profile {{ vm_gpu_profile }}{% endif %}
            --storage default
            {% if is_clustered | default(false) %}--target {{ hostvars[item]['parent_host'] }}{% endif %}
          register: worker_vm_create
          failed_when: >
            worker_vm_create.rc != 0 and 
            "already exists" not in worker_vm_create.stderr and 
            "busy running" not in worker_vm_create.stderr
          changed_when: "'already exists' not in worker_vm_create.stderr"
          loop: "{{ groups['microk8s_workers'] }}"
          when:
            - "'microk8s_workers' in groups"
            - item not in vm_list.stdout
            - ((is_clustered | default(false)) and (inventory_hostname == groups['baremetal'][0])) or (not is_clustered and (inventory_hostname == hostvars[item]['parent_host']))
          become: true
          run_once: "{{ is_clustered | default(false) }}"
        
        # Wait for VMs to initialize
        - name: Wait for VMs to initialize
          ansible.builtin.pause:
            seconds: 10
          when: control_vm_create is changed or worker_vm_create is changed
      tags: create_vms
    
    # Phase 3: Configure VM resources
    - name: Configure VM resources
      block:
        # Stop VMs before configuring resources
        - name: Stop VMs to configure resources
          ansible.builtin.command: lxc stop {{ item }} --force
          register: stop_vm_result
          failed_when: 
            - stop_vm_result.rc != 0
            - '"already stopped" not in stop_vm_result.stderr'
            - '"not found" not in stop_vm_result.stderr'
          loop: "{{ groups['microk8s_control_plane'] + groups['microk8s_workers'] }}"
          when: control_vm_create is changed or worker_vm_create is changed
          delegate_to: "{{ groups['baremetal'][0] }}"
          become: true
          run_once: true
          
        # Configure resources all at once using a shell script to avoid simultaneous changes
        - name: Configure all VM resources (CPU, memory, disk, secure boot)
          ansible.builtin.shell: |
            #!/bin/bash
            # Process each VM individually with direct commands instead of functions
            {% for vm in groups['microk8s_control_plane'] + groups['microk8s_workers'] %}
            echo "=== Configuring resources for VM {{ vm }} ==="
            
            # Configure CPU limit
            echo "Configuring limits.cpu={{ hostvars[vm]['cpu_cores'] }} for VM {{ vm }}"
            for i in 1 2 3; do
              if lxc config set "{{ vm }}" "limits.cpu" "{{ hostvars[vm]['cpu_cores'] }}" 2>/dev/null; then
                echo "Successfully set limits.cpu={{ hostvars[vm]['cpu_cores'] }} for VM {{ vm }} on attempt $i"
                break
              else
                echo "Failed to set limits.cpu={{ hostvars[vm]['cpu_cores'] }} for VM {{ vm }} on attempt $i, will retry in 2 seconds"
                sleep 2
                if [ $i -eq 3 ]; then
                  echo "Failed to set limits.cpu={{ hostvars[vm]['cpu_cores'] }} for VM {{ vm }} after 3 attempts"
                fi
              fi
            done
            
            # Configure memory limit
            echo "Configuring limits.memory={{ hostvars[vm]['memory'] }} for VM {{ vm }}"
            for i in 1 2 3; do
              if lxc config set "{{ vm }}" "limits.memory" "{{ hostvars[vm]['memory'] }}" 2>/dev/null; then
                echo "Successfully set limits.memory={{ hostvars[vm]['memory'] }} for VM {{ vm }} on attempt $i"
                break
              else
                echo "Failed to set limits.memory={{ hostvars[vm]['memory'] }} for VM {{ vm }} on attempt $i, will retry in 2 seconds"
                sleep 2
                if [ $i -eq 3 ]; then
                  echo "Failed to set limits.memory={{ hostvars[vm]['memory'] }} for VM {{ vm }} after 3 attempts"
                fi
              fi
            done
            
            # Configure disk size
            echo "Configuring device root size={{ hostvars[vm]['disk_size'] }} for VM {{ vm }}"
            for i in 1 2 3; do
              if lxc config device set "{{ vm }}" "root" "size={{ hostvars[vm]['disk_size'] }}" 2>/dev/null; then
                echo "Successfully set device root size={{ hostvars[vm]['disk_size'] }} for VM {{ vm }} on attempt $i"
                break
              else
                echo "Failed to set device root size={{ hostvars[vm]['disk_size'] }} for VM {{ vm }} on attempt $i, will retry in 2 seconds"
                sleep 2
                if [ $i -eq 3 ]; then
                  echo "Failed to set device root size={{ hostvars[vm]['disk_size'] }} for VM {{ vm }} after 3 attempts"
                  lxc config device show "{{ vm }}" "root" 2>/dev/null | grep -q "size:" && echo "Device root exists, but size configuration failed" || echo "Device root does not exist for VM {{ vm }}"
                fi
              fi
            done
            
            # Disable secure boot
            echo "Configuring security.secureboot=false for VM {{ vm }}"
            for i in 1 2 3; do
              if lxc config set "{{ vm }}" "security.secureboot" "false" 2>/dev/null; then
                echo "Successfully set security.secureboot=false for VM {{ vm }} on attempt $i"
                break
              else
                echo "Failed to set security.secureboot=false for VM {{ vm }} on attempt $i, will retry in 2 seconds"
                sleep 2
                if [ $i -eq 3 ]; then
                  echo "Failed to set security.secureboot=false for VM {{ vm }} after 3 attempts"
                fi
              fi
            done
            
            echo "=== Completed resource configuration for VM {{ vm }} ==="
            {% endfor %}
          register: resource_config
          delegate_to: "{{ groups['baremetal'][0] }}"
          become: true
          run_once: true
          
        # Start VMs with new configuration
        - name: Start VMs with new resource configurations
          ansible.builtin.command: lxc start {{ item }}
          register: start_vm_result
          failed_when: 
            - start_vm_result.rc != 0
            - '"already running" not in start_vm_result.stderr'
            - '"not found" not in start_vm_result.stderr'
          changed_when: start_vm_result.rc == 0
          loop: "{{ groups['microk8s_control_plane'] + groups['microk8s_workers'] }}"
          delegate_to: "{{ groups['baremetal'][0] }}"
          become: true
          run_once: true
          
        # Wait for VMs to be ready
        - name: Wait for VMs to be ready after resource configuration
          ansible.builtin.command: lxc exec {{ item }} -- echo ready
          register: vm_ready
          until: vm_ready.rc == 0
          retries: 30
          delay: 5
          loop: "{{ groups['microk8s_control_plane'] + groups['microk8s_workers'] }}"
          delegate_to: "{{ groups['baremetal'][0] }}"
          failed_when: false
          become: true
          run_once: "{{ is_clustered | default(false) }}"
      tags: configure_resources
    
    # Phase 4: Configure VM networking
    - name: Configure VM networking
      block:
        # Generate network configuration from template
        - name: Generate network configuration from template
          ansible.builtin.template:
            src: "{{ playbook_dir }}/templates/netplan_config.j2"
            dest: "/tmp/netplan_{{ item }}.yaml"
            mode: '0644'
          loop: "{{ groups['microk8s_control_plane'] + groups['microk8s_workers'] }}"
          delegate_to: "{{ hostvars[item]['parent_host'] }}"
          vars:
            internal_ip: "{{ hostvars[item]['internal_ip'] }}"
            lan_ip: "{{ hostvars[item]['lan_ip'] }}"
          
        # Copy network configuration to VMs
        - name: Copy network configuration to VMs
          ansible.builtin.command: >
            lxc file push /tmp/netplan_{{ item }}.yaml {{ item }}/etc/netplan/50-cloud-init.yaml
          loop: "{{ groups['microk8s_control_plane'] + groups['microk8s_workers'] }}"
          delegate_to: "{{ hostvars[item]['parent_host'] }}"
          become: true
          
        # Apply network configuration in VMs
        - name: Apply network configuration in VMs
          ansible.builtin.command: lxc exec {{ item }} -- netplan apply
          register: netplan_apply
          failed_when: netplan_apply.rc != 0
          loop: "{{ groups['microk8s_control_plane'] + groups['microk8s_workers'] }}"
          delegate_to: "{{ hostvars[item]['parent_host'] }}"
          become: true
          
        # Configure persistent DNS
        - name: Configure persistent DNS settings in VMs
          ansible.builtin.shell: >
            lxc exec {{ item }} -- bash -c 'mkdir -p /etc/systemd/resolved.conf.d';
            lxc exec {{ item }} -- bash -c '[ -f /etc/systemd/resolved.conf ] && cp /etc/systemd/resolved.conf /etc/systemd/resolved.conf.bak || true';
            
            lxc exec {{ item }} -- bash -c 'cat > /etc/systemd/resolved.conf << EOF
            [Resolve]
            DNS=8.8.8.8 8.8.4.4
            Domains=~thinkube.com ~kn.thinkube.com
            DNSStubListener=yes
            Cache=yes
            DNSStubListenerExtra=192.168.100.1
            EOF';
            
            lxc exec {{ item }} -- bash -c 'cat > /etc/resolv.conf << EOF
            nameserver 8.8.8.8
            nameserver 8.8.4.4
            search thinkube.com kn.thinkube.com
            EOF';
            
            lxc exec {{ item }} -- bash -c 'chattr +i /etc/resolv.conf || true';
            lxc exec {{ item }} -- systemctl restart systemd-resolved || true;
          register: dns_config
          failed_when: dns_config.rc != 0
          loop: "{{ groups['microk8s_control_plane'] + groups['microk8s_workers'] }}"
          delegate_to: "{{ hostvars[item]['parent_host'] }}"
          become: true
          
        # Clean up temporary network configuration files
        - name: Clean up temporary network configuration files
          ansible.builtin.file:
            path: "/tmp/netplan_{{ item }}.yaml"
            state: absent
          loop: "{{ groups['microk8s_control_plane'] + groups['microk8s_workers'] }}"
          delegate_to: "{{ hostvars[item]['parent_host'] }}"
      tags: configure_networking
    
    # Phase 5: Set up user and SSH access
    - name: Set up user and SSH access
      block:
        # Create thinkube user with proper permissions
        - name: Create thinkube user with proper permissions
          ansible.builtin.command: >
            lxc exec {{ item }} -- useradd -m -s /bin/bash thinkube
          register: create_user
          failed_when: create_user.rc != 0 and "already exists" not in create_user.stderr
          loop: "{{ groups['microk8s_control_plane'] + groups['microk8s_workers'] }}"
          delegate_to: "{{ hostvars[item]['parent_host'] }}"
          become: true
          
        # Set thinkube user password
        - name: Set thinkube user password
          ansible.builtin.command: >
            lxc exec {{ item }} -- bash -c "echo 'thinkube:{{ lookup('env', 'ANSIBLE_SUDO_PASS') }}' | chpasswd"
          register: set_password
          failed_when: set_password.rc != 0
          loop: "{{ groups['microk8s_control_plane'] + groups['microk8s_workers'] }}"
          delegate_to: "{{ hostvars[item]['parent_host'] }}"
          become: true
          
        # Add thinkube to sudo group
        - name: Add thinkube to sudo group
          ansible.builtin.command: >
            lxc exec {{ item }} -- usermod -aG sudo thinkube
          register: add_sudo
          failed_when: add_sudo.rc != 0
          loop: "{{ groups['microk8s_control_plane'] + groups['microk8s_workers'] }}"
          delegate_to: "{{ hostvars[item]['parent_host'] }}"
          become: true
          
        # Configure SSH for external access
        - name: Configure SSH for external access
          ansible.builtin.shell: |
            # Enable SSH service
            lxc exec {{ item }} -- systemctl enable ssh
            lxc exec {{ item }} -- systemctl start ssh
            
            # Enable password authentication
            lxc exec {{ item }} -- sed -i 's/^#\?PasswordAuthentication.*/PasswordAuthentication yes/' /etc/ssh/sshd_config
            
            # Restart SSH service to apply changes
            lxc exec {{ item }} -- systemctl restart ssh
            
            # Setup SSH directory for thinkube user
            lxc exec {{ item }} -- mkdir -p /home/thinkube/.ssh
            lxc exec {{ item }} -- chown thinkube:thinkube /home/thinkube/.ssh
            lxc exec {{ item }} -- chmod 700 /home/thinkube/.ssh
          register: ssh_config
          failed_when: ssh_config.rc != 0
          loop: "{{ groups['microk8s_control_plane'] + groups['microk8s_workers'] }}"
          delegate_to: "{{ hostvars[item]['parent_host'] }}"
          become: true
      tags: user_setup
    
    # Phase 6: Install essential packages
    - name: Install essential packages
      block:
        # Make sure VMs are properly running by ensuring they've fully booted
        - name: Ensure VMs are properly booted
          ansible.builtin.command: lxc restart {{ item }}
          register: restart_vm
          failed_when: restart_vm.rc != 0 and "already running" not in restart_vm.stderr
          changed_when: restart_vm.rc == 0
          loop: "{{ groups['microk8s_control_plane'] + groups['microk8s_workers'] }}"
          delegate_to: "{{ hostvars[item]['parent_host'] }}"
          become: true
        
        # Wait for VMs to be fully restarted
        - name: Wait for VMs to be ready after restart
          ansible.builtin.pause:
            seconds: 30
          when: restart_vm is changed
        
        # Configure host for proper VM networking - applied to all cluster nodes
        - name: Enable IP forwarding
          ansible.builtin.command: sysctl -w net.ipv4.ip_forward=1
          become: true
          changed_when: true
          
        - name: Create IP forwarding config file
          ansible.builtin.copy:
            content: "net.ipv4.ip_forward=1"
            dest: /etc/sysctl.d/99-vm-networking.conf
            mode: '0644'
          become: true
          
        - name: Apply sysctl settings
          ansible.builtin.command: sysctl -p /etc/sysctl.d/99-vm-networking.conf
          become: true
          changed_when: true
          
        - name: Ensure iptables is installed
          ansible.builtin.apt:
            name:
              - iptables
              - iptables-persistent
            state: present
            update_cache: yes
          become: true
          register: iptables_install
          failed_when: false
          
        - name: Set up NAT for VM traffic (lxdbr0)
          ansible.builtin.iptables:
            table: nat
            chain: POSTROUTING
            source: 192.168.100.0/24
            jump: MASQUERADE
            state: present
          become: true
          register: iptables_nat
          failed_when: false
          
        - name: Set up forwarding for outbound VM traffic
          ansible.builtin.iptables:
            chain: FORWARD
            in_interface: lxdbr0
            jump: ACCEPT
            state: present
          become: true
          register: iptables_forward_out
          failed_when: false
          
        - name: Set up forwarding for inbound VM traffic
          ansible.builtin.iptables:
            chain: FORWARD
            out_interface: lxdbr0
            jump: ACCEPT
            state: present
            ctstate: RELATED,ESTABLISHED
          become: true
          register: iptables_forward_in
          failed_when: false
          
        - name: Save iptables rules
          ansible.builtin.shell: >
            mkdir -p /etc/iptables && 
            iptables-save > /etc/iptables/rules.v4
          become: true
          changed_when: true
          
        - name: Configure lxdbr0 network
          ansible.builtin.command: >
            lxc network set lxdbr0 ipv4.address=192.168.100.1/24
          become: true
          register: lxdbr0_ip
          failed_when: false
          changed_when: true
          
        - name: Enable NAT on lxdbr0
          ansible.builtin.command: >
            lxc network set lxdbr0 ipv4.nat=true
          become: true
          register: lxdbr0_nat
          failed_when: false
          changed_when: true
          
        - name: Disable DHCP on lxdbr0
          ansible.builtin.command: >
            lxc network set lxdbr0 ipv4.dhcp=false
          become: true
          register: lxdbr0_dhcp
          failed_when: false
          changed_when: true
          
        - name: Set DNS mode on lxdbr0
          ansible.builtin.command: >
            lxc network set lxdbr0 dns.mode=managed
          become: true
          register: lxdbr0_dns_mode
          failed_when: false
          changed_when: true
          
        - name: Set DNS domain on lxdbr0
          ansible.builtin.command: >
            lxc network set lxdbr0 dns.domain=lxd
          become: true
          register: lxdbr0_dns_domain
          failed_when: false
          changed_when: true
          
        # Fix VM networking step by step
        
        # 1. Show VM network interfaces first
        - name: Show VM network interfaces 
          ansible.builtin.command: lxc exec {{ item }} -- ip addr
          register: vm_interfaces
          loop: "{{ groups['microk8s_control_plane'] + groups['microk8s_workers'] }}"
          delegate_to: "{{ hostvars[item]['parent_host'] }}"
          become: true
          changed_when: false
        
        # 2. Configure DNS
        - name: Configure DNS in VMs
          ansible.builtin.shell: |
            lxc exec {{ item }} -- bash -c 'echo "nameserver 8.8.8.8" > /etc/resolv.conf'
            lxc exec {{ item }} -- bash -c 'echo "nameserver 8.8.4.4" >> /etc/resolv.conf'
          loop: "{{ groups['microk8s_control_plane'] + groups['microk8s_workers'] }}"
          delegate_to: "{{ hostvars[item]['parent_host'] }}"
          become: true
        
        # 3. Create proper netplan config
        - name: Create proper netplan configuration
          ansible.builtin.shell: |
            lxc exec {{ item }} -- bash -c 'cat > /etc/netplan/50-cloud-init.yaml << EOF
            network:
              version: 2
              ethernets:
                enp5s0:
                  dhcp4: false
                  addresses: [{{ hostvars[item]['internal_ip'] }}/24]
                  routes:
                    - to: default
                      via: 192.168.100.1
                  nameservers:
                    addresses: [8.8.8.8, 8.8.4.4]
                enp6s0:
                  dhcp4: false
                  addresses: [{{ hostvars[item]['lan_ip'] }}/24]
                  routes:
                    - to: default
                      via: {{ network_gateway }}
                  nameservers:
                    addresses: [8.8.8.8, 8.8.4.4]
            EOF'
          loop: "{{ groups['microk8s_control_plane'] + groups['microk8s_workers'] }}"
          delegate_to: "{{ hostvars[item]['parent_host'] }}"
          become: true
        
        # 4. Apply netplan
        - name: Apply netplan configuration
          ansible.builtin.command: lxc exec {{ item }} -- netplan apply
          register: netplan_apply
          failed_when: false
          loop: "{{ groups['microk8s_control_plane'] + groups['microk8s_workers'] }}"
          delegate_to: "{{ hostvars[item]['parent_host'] }}"
          become: true
        
        # 5. Enable IP forwarding in VM
        - name: Enable IP forwarding in VM
          ansible.builtin.command: lxc exec {{ item }} -- sysctl -w net.ipv4.ip_forward=1
          loop: "{{ groups['microk8s_control_plane'] + groups['microk8s_workers'] }}"
          delegate_to: "{{ hostvars[item]['parent_host'] }}"
          become: true
          failed_when: false
        
        # 6. Check if networking is working
        - name: Check if networking is working
          ansible.builtin.command: lxc exec {{ item }} -- ping -c 2 8.8.8.8
          register: ping_test
          failed_when: false
          loop: "{{ groups['microk8s_control_plane'] + groups['microk8s_workers'] }}"
          delegate_to: "{{ hostvars[item]['parent_host'] }}"
          become: true
        
        # 7. Show final VM network configuration
        - name: Show final VM network configuration
          ansible.builtin.command: lxc exec {{ item }} -- ip route
          register: final_routes
          loop: "{{ groups['microk8s_control_plane'] + groups['microk8s_workers'] }}"
          delegate_to: "{{ hostvars[item]['parent_host'] }}"
          become: true
          changed_when: false
        
        # 8. Display network status
        - name: Display network status for each VM
          ansible.builtin.debug:
            msg: |
              ════════════════════════════════════════════════════════════════════════
              NETWORK STATUS FOR VM: {{ item }}
              ════════════════════════════════════════════════════════════════════════
              
              Network setup completed.
              Check VM network routes to verify connectivity.
              
              ════════════════════════════════════════════════════════════════════════
          loop: "{{ groups['microk8s_control_plane'] + groups['microk8s_workers'] }}"
          
        # 9. Continue with package installation, but skip update if network failed
        # We might still be able to install packages from cache
          
        # Fix DNS before package installation to ensure repository access
        - name: Fix DNS for package installation
          ansible.builtin.shell: >
            lxc exec {{ item }} -- bash -c 'cat > /etc/resolv.conf << EOF
            nameserver 8.8.8.8
            nameserver 8.8.4.4
            EOF';
            
            timeout 5 lxc exec {{ item }} -- bash -c 'host -t A google.com' || true;
            timeout 5 lxc exec {{ item }} -- bash -c 'host -t A archive.ubuntu.com' || true;
          register: dns_fix
          failed_when: false
          loop: "{{ groups['microk8s_control_plane'] + groups['microk8s_workers'] }}"
          delegate_to: "{{ hostvars[item]['parent_host'] }}"
          become: true
        
        # Check network connectivity to package repositories with retries
        - name: Check if we can access package repositories with retries
          ansible.builtin.shell: |
            for i in $(seq 1 3); do
              # Try pinging the Ubuntu archive server
              if lxc exec {{ item }} -- timeout 5 ping -c 1 archive.ubuntu.com; then
                echo "Repository access successful on attempt $i"
                exit 0
              else
                echo "Repository access failed on attempt $i"
                # Short pause before retry
                sleep 2
              fi
            done
            echo "All repository access attempts failed"
            exit 1
          register: repo_access
          failed_when: false
          loop: "{{ groups['microk8s_control_plane'] + groups['microk8s_workers'] }}"
          delegate_to: "{{ hostvars[item]['parent_host'] }}"
          become: true
        
        # Update package cache with retries
        - name: Update package cache with retries
          ansible.builtin.shell: |
            for i in $(seq 1 3); do
              if lxc exec {{ item }} -- apt-get update -y; then
                echo "Package cache update successful on attempt $i"
                exit 0
              else
                echo "Package cache update failed on attempt $i"
                # Short pause before retry
                sleep 2
              fi
            done
            echo "All package cache update attempts failed"
            exit 1
          register: apt_update
          failed_when: false
          loop: "{{ groups['microk8s_control_plane'] + groups['microk8s_workers'] }}"
          delegate_to: "{{ hostvars[item]['parent_host'] }}"
          become: true
          
        # Install essential packages with retries - simplified for syntax
        - name: Install essential packages in VMs
          ansible.builtin.command: >
            lxc exec {{ item }} -- bash -c "export DEBIAN_FRONTEND=noninteractive && 
            apt-get update -y && 
            apt-get install -y --no-install-recommends snapd openssh-server curl wget dnsutils net-tools iptables chrony"
          register: pkg_install
          failed_when: false
          loop: "{{ groups['microk8s_control_plane'] + groups['microk8s_workers'] }}"
          delegate_to: "{{ hostvars[item]['parent_host'] }}"
          become: true
          
        # Try to fix any broken packages
        - name: Fix broken packages if needed
          ansible.builtin.command: >
            lxc exec {{ item }} -- apt-get -f install -y
          register: pkg_fix
          failed_when: false
          loop: "{{ groups['microk8s_control_plane'] + groups['microk8s_workers'] }}"
          delegate_to: "{{ hostvars[item]['parent_host'] }}"
          become: true
          
        # Configure services regardless of installation success
        - name: Configure services
          ansible.builtin.shell: |
            #!/bin/bash
            # Reset failed services
            lxc exec {{ item }} -- systemctl reset-failed || true
            # Reload systemd daemon
            lxc exec {{ item }} -- systemctl daemon-reload
            
            # Configure SSH service
            echo "Configuring ssh service..."
            if lxc exec {{ item }} -- bash -c "[ -f /lib/systemd/system/ssh.service ] || [ -f /etc/systemd/system/ssh.service ]"; then
              echo "ssh service found, attempting to enable and start"
              lxc exec {{ item }} -- systemctl enable ssh && echo "ssh service enabled" || echo "Failed to enable ssh service"
              lxc exec {{ item }} -- systemctl start ssh && echo "ssh service started" || echo "Failed to start ssh service"
              lxc exec {{ item }} -- systemctl status ssh --no-pager || true
            else
              echo "ssh service not found"
            fi
            
            # Configure chrony service
            echo "Configuring chrony service..."
            if lxc exec {{ item }} -- bash -c "[ -f /lib/systemd/system/chrony.service ] || [ -f /etc/systemd/system/chrony.service ]"; then
              echo "chrony service found, attempting to enable and start"
              lxc exec {{ item }} -- systemctl enable chrony && echo "chrony service enabled" || echo "Failed to enable chrony service"
              lxc exec {{ item }} -- systemctl start chrony && echo "chrony service started" || echo "Failed to start chrony service"
              lxc exec {{ item }} -- systemctl status chrony --no-pager || true
            else
              echo "chrony service not found"
            fi
            
            # Configure systemd-resolved service
            echo "Configuring systemd-resolved service..."
            if lxc exec {{ item }} -- bash -c "[ -f /lib/systemd/system/systemd-resolved.service ] || [ -f /etc/systemd/system/systemd-resolved.service ]"; then
              echo "systemd-resolved service found, attempting to enable and start"
              lxc exec {{ item }} -- systemctl enable systemd-resolved && echo "systemd-resolved service enabled" || echo "Failed to enable systemd-resolved service"
              lxc exec {{ item }} -- systemctl start systemd-resolved && echo "systemd-resolved service started" || echo "Failed to start systemd-resolved service"
              lxc exec {{ item }} -- systemctl status systemd-resolved --no-pager || true
            else
              echo "systemd-resolved service not found"
            fi
            
            echo "Service configuration completed for {{ item }}"
          register: services_config
          failed_when: false
          loop: "{{ groups['microk8s_control_plane'] + groups['microk8s_workers'] }}"
          delegate_to: "{{ hostvars[item]['parent_host'] }}"
          become: true
                    
        # Collect VM status information 
        - name: Collect VM status information
          ansible.builtin.shell: >
            echo "Collecting status for VM: {{ item }}";
            
            echo "--- NETWORK STATUS ---";
            lxc exec {{ item }} -- ip -br addr || echo "Failed to get IP addresses";
            lxc exec {{ item }} -- ip -br route || echo "Failed to get routing table";
            
            echo "--- DNS STATUS ---";  
            lxc exec {{ item }} -- cat /etc/resolv.conf || echo "Failed to get resolv.conf";
            lxc exec {{ item }} -- timeout 5 host -t A google.com || echo "DNS resolution failed";
            
            echo "--- SERVICE STATUS ---";
            lxc exec {{ item }} -- systemctl is-active ssh systemd-resolved chrony || echo "Service check failed";
            
            if lxc exec {{ item }} -- ping -c 1 -W 2 8.8.8.8 >/dev/null 2>&1; then
              echo "NETWORK: ONLINE";
            else
              echo "NETWORK: OFFLINE";
            fi;
            
            if lxc exec {{ item }} -- host -t A google.com >/dev/null 2>&1; then
              echo "DNS: WORKING";
            else
              echo "DNS: FAILED";
            fi;
            
            if lxc exec {{ item }} -- systemctl is-active ssh >/dev/null 2>&1; then
              echo "SSH: RUNNING";
            else
              echo "SSH: NOT RUNNING";
            fi;
          register: vm_status
          failed_when: false
          loop: "{{ groups['microk8s_control_plane'] + groups['microk8s_workers'] }}"
          delegate_to: "{{ hostvars[item]['parent_host'] }}"
          become: true
          
        # Display installation summary
        - name: Display installation summary
          ansible.builtin.debug:
            msg: |
              ════════════════════════════════════════════════════════════════════════
              VM SETUP SUMMARY
              ════════════════════════════════════════════════════════════════════════
              
              Basic VM setup completed with the following components:
              
              1. VM CREATION:
                 ✓ VM instances created with proper profiles
                 ✓ Resources allocated according to inventory
              
              2. NETWORK CONFIGURATION:
                 ✓ Internal network (lxdbr0) configured
                 ✓ External network (br0) configured
                 ✓ Host NAT and forwarding configured
                 ✓ Netplan configuration applied
              
              3. USER SETUP:
                 ✓ thinkube user created
                 ✓ SSH access configured
              
              4. DNS CONFIGURATION:
                 ✓ Static DNS configuration applied
                 ✓ systemd-resolved configured
              
              5. PACKAGE INSTALLATION:
                 ✓ Package installation attempted
                 ✓ SSH and system services configured
              
              VM STATUS OVERVIEW:
              {% for result in vm_status.results | default([]) %}
              {% if result is defined and result.stdout is defined %}
              - {{ result.item }}:
                {{ result.stdout | regex_search("NETWORK: (ONLINE|OFFLINE)") | default("NETWORK: UNKNOWN") }}
                {{ result.stdout | regex_search("DNS: (WORKING|FAILED)") | default("DNS: UNKNOWN") }}
                {{ result.stdout | regex_search("SSH: (RUNNING|NOT RUNNING)") | default("SSH: UNKNOWN") }}
              {% endif %}
              {% endfor %}
              
              NEXT STEPS:
                Run the ZeroTier setup playbook:
                ansible-playbook -i inventory/inventory.yaml ansible/vm_deployment/30_setup_zerotier.yaml
              
              ════════════════════════════════════════════════════════════════════════
      tags: install_packages
    
    # Phase 7: Create and run network diagnostics script
    - name: Create network diagnostics script
      block:
        # Generate network test script
        - name: Generate network test script
          ansible.builtin.template:
            src: "{{ playbook_dir }}/templates/network_test.j2"
            dest: "/tmp/network_test_{{ item }}.sh"
            mode: '0755'
          loop: "{{ groups['microk8s_control_plane'] + groups['microk8s_workers'] }}"
          delegate_to: "{{ hostvars[item]['parent_host'] }}"
          
        # Copy network test script to VMs
        - name: Copy network test script to VMs
          ansible.builtin.command: >
            lxc file push /tmp/network_test_{{ item }}.sh {{ item }}/tmp/network_test.sh
          loop: "{{ groups['microk8s_control_plane'] + groups['microk8s_workers'] }}"
          delegate_to: "{{ hostvars[item]['parent_host'] }}"
          become: true
          
        # Make script executable
        - name: Make network test script executable
          ansible.builtin.command: >
            lxc exec {{ item }} -- chmod +x /tmp/network_test.sh
          loop: "{{ groups['microk8s_control_plane'] + groups['microk8s_workers'] }}"
          delegate_to: "{{ hostvars[item]['parent_host'] }}"
          become: true
          
        # Run network diagnostics script
        - name: Run network diagnostics script
          ansible.builtin.command: >
            lxc exec {{ item }} -- /tmp/network_test.sh
          register: network_test
          failed_when: network_test.rc != 0
          loop: "{{ groups['microk8s_control_plane'] + groups['microk8s_workers'] }}"
          delegate_to: "{{ hostvars[item]['parent_host'] }}"
          become: true
          
        # Display network test results
        - name: Display network test results
          ansible.builtin.debug:
            msg: |
              ════════════════════════════════════════════════════════════════════════
              NETWORK TEST RESULTS FOR {{ item.item }}
              ════════════════════════════════════════════════════════════════════════
              
              {{ item.stdout | default('No output available') }}
              
              ════════════════════════════════════════════════════════════════════════
          loop: "{{ network_test.results | default([]) }}"
          when: network_test is defined and network_test.results is defined
          
        # Clean up temporary files
        - name: Clean up temporary network test files
          ansible.builtin.file:
            path: "/tmp/network_test_{{ item }}.sh"
            state: absent
          loop: "{{ groups['microk8s_control_plane'] + groups['microk8s_workers'] }}"
          delegate_to: "{{ hostvars[item]['parent_host'] }}"
      tags: network_test
    
    # Phase 8: Generate ZeroTier setup script
    - name: Generate ZeroTier setup script
      block:
        # Check if ZeroTier network ID is available
        - name: Check if ZeroTier network ID is available
          ansible.builtin.fail:
            msg: "ZeroTier network ID not found. Please define zerotier_network_id in inventory variables or set ZEROTIER_NETWORK_ID environment variable."
          when: >
            hostvars['all']['vars']['zerotier_network_id'] is not defined and
            lookup('env', 'ZEROTIER_NETWORK_ID') == ''
          
        # Generate ZeroTier setup script
        - name: Generate ZeroTier setup script
          ansible.builtin.template:
            src: "{{ playbook_dir }}/templates/zerotier_setup.j2"
            dest: "/tmp/zerotier_setup_{{ item }}.sh"
            mode: '0755'
          loop: "{{ groups['microk8s_control_plane'] + groups['microk8s_workers'] }}"
          delegate_to: "{{ hostvars[item]['parent_host'] }}"
          when: 
            - hostvars[item]['zerotier_enabled'] is defined
            - hostvars[item]['zerotier_enabled']
          vars:
            zerotier_network_id: "{{ lookup('env', 'ZEROTIER_NETWORK_ID') }}"
      tags: zerotier
    
    # Phase 9: Display VM creation status
    - name: Display VM status
      block:
        # List VMs on this host
        - name: List VMs on this host
          ansible.builtin.command: lxc list
          register: vm_list_final
          changed_when: false
          become: true
          
        # Display VM creation completion message
        - name: Display VM creation completion message
          ansible.builtin.debug:
            msg: |
              ════════════════════════════════════════════════════════════════════════
              ✅ LXD VMs Created Successfully on {{ inventory_hostname }}
              ════════════════════════════════════════════════════════════════════════
              
              {{ vm_list_final.stdout }}
              
              NEXT STEPS:
                Run the ZeroTier setup playbook:
                ansible-playbook -i inventory/inventory.yaml ansible/vm_deployment/30_setup_zerotier.yaml
              
              ════════════════════════════════════════════════════════════════════════
      tags: status