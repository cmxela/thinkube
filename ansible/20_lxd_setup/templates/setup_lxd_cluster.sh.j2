#!/bin/bash
# setup_lxd_cluster.sh - Setup LXD cluster across baremetal hosts
# This script is generated from a template by Ansible

set -e  # Exit on any error

# Configuration from inventory
CLUSTER_NAME="{{ cluster_name | default('thinkube-lxd-cluster') }}"
PRIMARY_NODE="bcn1"
PRIMARY_IP="{{ hostvars['bcn1']['ansible_host'] }}"
SECONDARY_NODE="bcn2"
SECONDARY_IP="{{ hostvars['bcn2']['ansible_host'] }}"
CLUSTER_PORT="{{ cluster_port | default(8443) }}"
LXD_TRUST_PASSWORD="{{ lxd_trust_password }}"
MAX_RETRIES=5

# Load sudo password
if [ -f ~/.env ]; then
  source ~/.env
fi

# Colors for output
GREEN='\033[0;32m'
RED='\033[0;31m'
YELLOW='\033[0;33m'
NC='\033[0m' # No Color

# Display banner
echo -e "${GREEN}═════════════════════════════════════════════════════════${NC}"
echo -e "${GREEN}   Setting up LXD Cluster across Baremetal Hosts${NC}"
echo -e "${GREEN}═════════════════════════════════════════════════════════${NC}"
echo -e "${GREEN}Cluster Name: ${NC}$CLUSTER_NAME"
echo -e "${GREEN}Primary Node: ${NC}$PRIMARY_NODE ($PRIMARY_IP)"
echo -e "${GREEN}Secondary Node: ${NC}$SECONDARY_NODE ($SECONDARY_IP)"
echo -e "${GREEN}═════════════════════════════════════════════════════════${NC}"

# Reset functionality is now handled in the main function

# Function to check if a node is already in a cluster
check_cluster() {
  local node=$1
  echo -e "${YELLOW}Checking if $node is already in a cluster...${NC}"
  if ssh $node "echo $ANSIBLE_SUDO_PASS | sudo -S lxc cluster list 2>/dev/null | grep -q $node"; then
    echo -e "${GREEN}$node is already part of a cluster.${NC}"
    return 0  # True
  else
    echo -e "${YELLOW}$node is not part of a cluster.${NC}"
    return 1  # False
  fi
}

# Phase 1: Initialize LXD cluster on primary node
initialize_primary_node() {
  echo -e "${YELLOW}Initializing LXD cluster on $PRIMARY_NODE...${NC}"
  
  # Create initialization config
  cat > /tmp/lxd_init.yaml << EOF
config:
  core.https_address: ${PRIMARY_IP}:${CLUSTER_PORT}
  core.trust_password: ${LXD_TRUST_PASSWORD}
cluster:
  enabled: true
  server_name: $PRIMARY_NODE
storage_pools:
- name: default
  driver: dir
  config: {}
networks:
- name: lxdbr0
  type: bridge
  config:
    ipv4.address: {{ lxdbr0_ipv4_address | default('192.168.100.1/24') }}
    ipv4.nat: "true"
    ipv6.address: {{ lxdbr0_ipv6_address | default('fd42:d2f8:c3f:9338::1/64') }}
    ipv6.nat: "true"
    dns.mode: managed
    dns.domain: lxd
profiles:
- name: default
  devices:
    eth0:
      name: eth0
      network: lxdbr0
      type: nic
    root:
      path: /
      pool: default
      type: disk
EOF

  # Copy config to primary node
  scp /tmp/lxd_init.yaml $PRIMARY_NODE:/tmp/lxd_init.yaml
  
  # Initialize LXD on primary node
  ssh $PRIMARY_NODE "echo $ANSIBLE_SUDO_PASS | sudo -S snap stop lxd || true; sleep 5; echo $ANSIBLE_SUDO_PASS | sudo -S snap start lxd; sleep 10; echo $ANSIBLE_SUDO_PASS | sudo -S bash -c 'cat /tmp/lxd_init.yaml | lxd init --preseed'; sleep 5; echo $ANSIBLE_SUDO_PASS | sudo -S snap restart lxd; sleep 15"
  
  # Verify initialization
  for i in $(seq 1 $MAX_RETRIES); do
    if ssh $PRIMARY_NODE "echo $ANSIBLE_SUDO_PASS | sudo -S lxc cluster list | grep -q $PRIMARY_NODE"; then
      echo -e "${GREEN}✅ LXD cluster initialized successfully on $PRIMARY_NODE${NC}"
      return 0
    fi
    echo -e "${YELLOW}Waiting for cluster to initialize on $PRIMARY_NODE... (attempt $i/$MAX_RETRIES)${NC}"
    sleep 10
  done
  
  echo -e "${RED}❌ Failed to initialize LXD cluster on $PRIMARY_NODE after $MAX_RETRIES attempts${NC}"
  return 1
}

# We no longer need the get_certificate function with the token-based approach

# Phase 3: Join secondary node to the cluster using join token method
join_secondary_node() {
  echo -e "${YELLOW}Joining $SECONDARY_NODE to the LXD cluster...${NC}"

  # Get cluster address
  CLUSTER_ADDR="${PRIMARY_IP}:${CLUSTER_PORT}"
  echo -e "${YELLOW}Cluster address: $CLUSTER_ADDR${NC}"

  # Wait for the primary node to fully initialize
  echo -e "${YELLOW}Waiting for primary node to fully initialize before generating token...${NC}"
  sleep 30

  # Generate a join token on the primary node (following official approach)
  echo -e "${YELLOW}Generating join token on $PRIMARY_NODE...${NC}"
  TOKEN=$(ssh $PRIMARY_NODE "echo $ANSIBLE_SUDO_PASS | sudo -S lxc cluster add $SECONDARY_NODE" 2>&1)

  # Debug output
  echo -e "${YELLOW}Token generation output: $TOKEN${NC}"

  EXTRACTED_TOKEN=$(echo "$TOKEN" | grep -oP "lxd init.*\'" | sed "s/lxd init//g" | tr -d "'")

  if [ -z "$EXTRACTED_TOKEN" ]; then
    echo -e "${RED}❌ Failed to generate join token${NC}"
    echo -e "${YELLOW}Checking LXD logs for errors...${NC}"
    ssh $PRIMARY_NODE "echo $ANSIBLE_SUDO_PASS | sudo -S cat /var/snap/lxd/common/lxd/logs/lxd.log | tail -n 20"
    return 1
  fi

  TOKEN="$EXTRACTED_TOKEN"

  echo -e "${GREEN}✅ Join token generated successfully${NC}"

  # Reset the secondary node to prepare for joining
  echo -e "${YELLOW}Resetting $SECONDARY_NODE before joining...${NC}"
  reset_node $SECONDARY_NODE

  # Join using the token
  echo -e "${YELLOW}Joining $SECONDARY_NODE to cluster using token...${NC}"
  echo -e "${YELLOW}Using token: $TOKEN${NC}"

  # Create a script for the join process
  cat > /tmp/join_cluster.sh << EOF
#!/bin/bash
echo "$ANSIBLE_SUDO_PASS" | sudo -S lxc profile device remove default root || true
echo "$ANSIBLE_SUDO_PASS" | sudo -S lxc profile device remove default eth0 || true
echo "$ANSIBLE_SUDO_PASS" | sudo -S lxc storage delete default || true
echo "$ANSIBLE_SUDO_PASS" | sudo -S snap stop lxd || true
sleep 5
echo "$ANSIBLE_SUDO_PASS" | sudo -S rm -rf /var/snap/lxd/common/lxd/database || true
echo "$ANSIBLE_SUDO_PASS" | sudo -S rm -rf /var/snap/lxd/common/lxd/server.crt || true
echo "$ANSIBLE_SUDO_PASS" | sudo -S rm -rf /var/snap/lxd/common/lxd/server.key || true
echo "$ANSIBLE_SUDO_PASS" | sudo -S rm -rf /var/snap/lxd/common/lxd/cluster.key || true
echo "$ANSIBLE_SUDO_PASS" | sudo -S rm -rf /var/snap/lxd/common/lxd/storage-pools || true
echo "$ANSIBLE_SUDO_PASS" | sudo -S rm -rf /var/snap/lxd/common/lxd/networks || true
echo "$ANSIBLE_SUDO_PASS" | sudo -S snap start lxd
sleep 10

# Create a preseed file with the token
cat > /tmp/join.yaml << EOL
cluster:
  enabled: true
  token: "$TOKEN"
EOL

# Join the cluster using the token
echo "$ANSIBLE_SUDO_PASS" | sudo -S cat /tmp/join.yaml | sudo lxd init --preseed
EOF

  # Copy and execute the join script
  chmod +x /tmp/join_cluster.sh
  scp /tmp/join_cluster.sh $SECONDARY_NODE:/tmp/
  JOIN_RESULT=$(ssh $SECONDARY_NODE "bash /tmp/join_cluster.sh" 2>&1)
  echo -e "${YELLOW}Join result: $JOIN_RESULT${NC}"

  # Verify join
  for i in $(seq 1 $MAX_RETRIES); do
    if ssh $PRIMARY_NODE "echo $ANSIBLE_SUDO_PASS | sudo -S lxc cluster list | grep -q $SECONDARY_NODE"; then
      echo -e "${GREEN}✅ $SECONDARY_NODE successfully joined the cluster${NC}"
      return 0
    fi
    echo -e "${YELLOW}Waiting for $SECONDARY_NODE to appear in the cluster... (attempt $i/$MAX_RETRIES)${NC}"
    sleep 10
  done

  echo -e "${RED}❌ Failed to join $SECONDARY_NODE to the cluster after $MAX_RETRIES attempts${NC}"
  return 1
}

# Phase 4: Create VM profiles
create_profiles() {
  echo -e "${YELLOW}Creating VM profiles...${NC}"
  
  # Create vm-networks profile
  ssh $PRIMARY_NODE "cat > /tmp/vm-networks.yaml << EOF
name: vm-networks
description: \"Profile for VM networking setup\"
config:
  security.nesting: \"true\"
devices:
  eth0:
    name: eth0
    nictype: bridged
    parent: lxdbr0
    type: nic
  eth1:
    name: eth1
    nictype: bridged
    parent: br0
    type: nic
EOF
echo $ANSIBLE_SUDO_PASS | sudo -S lxc profile create vm-networks || true
echo $ANSIBLE_SUDO_PASS | sudo -S bash -c 'cat /tmp/vm-networks.yaml | lxc profile edit vm-networks'"

  # Create vm-resources profile
  ssh $PRIMARY_NODE "cat > /tmp/vm-resources.yaml << EOF
name: vm-resources
description: \"Profile for VM resource limits\"
config:
  limits.cpu: \"4\"
  limits.memory: \"4GB\"
  limits.memory.enforce: \"hard\"
  security.secureboot: \"false\"
  boot.autostart: \"true\"
devices: {}
EOF
echo $ANSIBLE_SUDO_PASS | sudo -S lxc profile create vm-resources || true
echo $ANSIBLE_SUDO_PASS | sudo -S bash -c 'cat /tmp/vm-resources.yaml | lxc profile edit vm-resources'"

  # Create vm-gpu profile
  ssh $PRIMARY_NODE "cat > /tmp/vm-gpu.yaml << EOF
name: vm-gpu
description: \"Profile for VM GPU passthrough\"
config:
  nvidia.driver.capabilities: \"all\"
  nvidia.runtime: \"true\"
devices: {}
EOF
echo $ANSIBLE_SUDO_PASS | sudo -S lxc profile create vm-gpu || true
echo $ANSIBLE_SUDO_PASS | sudo -S bash -c 'cat /tmp/vm-gpu.yaml | lxc profile edit vm-gpu'"

  echo -e "${GREEN}✅ VM profiles created successfully${NC}"
}

# Phase 5: Verify final cluster status
verify_cluster() {
  echo -e "${YELLOW}Verifying final cluster status...${NC}"
  
  ssh $PRIMARY_NODE "echo $ANSIBLE_SUDO_PASS | sudo -S lxc cluster list"
  
  # Check if both nodes are in the cluster
  if ssh $PRIMARY_NODE "echo $ANSIBLE_SUDO_PASS | sudo -S lxc cluster list | grep -q $PRIMARY_NODE" && ssh $PRIMARY_NODE "echo $ANSIBLE_SUDO_PASS | sudo -S lxc cluster list | grep -q $SECONDARY_NODE"; then
    echo -e "
${GREEN}═════════════════════════════════════════════════════════${NC}
${GREEN}✅ LXD Cluster Configuration Completed Successfully${NC}
${GREEN}═════════════════════════════════════════════════════════${NC}

The LXD cluster has been successfully set up across the following nodes:
$PRIMARY_NODE, $SECONDARY_NODE

PROFILES CREATED:
- vm-networks: Network configuration for VMs
- vm-resources: Resource limits for VMs
- vm-gpu: GPU passthrough configuration

NEXT STEPS:
Run the LXD profiles setup playbook:
$ ansible-playbook -i inventory/inventory.yaml ansible/20_lxd_setup/20_setup_lxd_profiles.yaml

${GREEN}═════════════════════════════════════════════════════════${NC}"
    return 0
  else
    echo -e "${RED}❌ Cluster verification failed. Not all nodes are in the cluster.${NC}"
    return 1
  fi
}

# Function to reset a node's cluster configuration
reset_node() {
  local node=$1
  echo -e "${YELLOW}Completely resetting LXD on $node...${NC}"

  # Stop LXD service
  ssh $node "echo $ANSIBLE_SUDO_PASS | sudo -S snap stop lxd || true"
  echo -e "${YELLOW}LXD service stopped on $node. Waiting...${NC}"
  sleep 5

  # First try to remove resources using LXD commands
  ssh $node "echo $ANSIBLE_SUDO_PASS | sudo -S lxc profile device remove default root || true;
             echo $ANSIBLE_SUDO_PASS | sudo -S lxc profile device remove default eth0 || true;
             echo $ANSIBLE_SUDO_PASS | sudo -S lxc storage delete default --force || true;
             echo $ANSIBLE_SUDO_PASS | sudo -S lxc network delete lxdbr0 || true;
             echo $ANSIBLE_SUDO_PASS | sudo -S snap set lxd cluster.address=\"\""

  # Then remove all LXD data directories to ensure a clean state
  ssh $node "echo $ANSIBLE_SUDO_PASS | sudo -S rm -rf /var/snap/lxd/common/lxd/database || true;
             echo $ANSIBLE_SUDO_PASS | sudo -S rm -rf /var/snap/lxd/common/lxd/server.crt || true;
             echo $ANSIBLE_SUDO_PASS | sudo -S rm -rf /var/snap/lxd/common/lxd/server.key || true;
             echo $ANSIBLE_SUDO_PASS | sudo -S rm -rf /var/snap/lxd/common/lxd/cluster.key || true;
             echo $ANSIBLE_SUDO_PASS | sudo -S rm -rf /var/snap/lxd/common/lxd/cluster.crt || true;
             echo $ANSIBLE_SUDO_PASS | sudo -S rm -rf /var/snap/lxd/common/lxd/storage-pools || true;
             echo $ANSIBLE_SUDO_PASS | sudo -S rm -rf /var/snap/lxd/common/lxd/networks || true;
             echo $ANSIBLE_SUDO_PASS | sudo -S rm -rf /var/snap/lxd/common/lxd/disks/default.img || true"

  # Start LXD service again
  ssh $node "echo $ANSIBLE_SUDO_PASS | sudo -S snap start lxd"
  echo -e "${YELLOW}LXD service restarted on $node. Waiting for initialization...${NC}"
  sleep 15

  # Verify reset was successful
  if ssh $node "echo $ANSIBLE_SUDO_PASS | sudo -S lxc storage list 2>/dev/null | grep -q default"; then
    echo -e "${RED}⚠️ Warning: Storage pool 'default' still exists on $node after reset${NC}"
  else
    echo -e "${GREEN}✅ Reset successful on $node${NC}"
  fi
}

# Main execution flow
main() {
  # Check LXD trust password on both nodes
  echo -e "${YELLOW}Verifying environment...${NC}"
  echo -e "${YELLOW}LXD Trust Password: $LXD_TRUST_PASSWORD${NC}"

  # Always reset both nodes to ensure a clean slate
  echo -e "${YELLOW}Performing clean reset of both nodes...${NC}"
  reset_node $PRIMARY_NODE
  reset_node $SECONDARY_NODE

  # Check if nodes are already in a cluster
  if check_cluster $PRIMARY_NODE && check_cluster $SECONDARY_NODE; then
    echo -e "${GREEN}Both nodes are already in a cluster. Proceeding to verify profiles.${NC}"
    verify_cluster
    exit 0
  fi

  # Initialize primary node if needed
  if ! check_cluster $PRIMARY_NODE; then
    initialize_primary_node || { echo -e "${RED}Failed to initialize primary node${NC}"; exit 1; }
  fi

  # Join secondary node if needed (we no longer need the certificate with the token approach)
  if ! check_cluster $SECONDARY_NODE; then
    join_secondary_node || { echo -e "${RED}Failed to join secondary node${NC}"; exit 1; }
  fi

  # Create profiles
  create_profiles || { echo -e "${RED}Failed to create profiles${NC}"; exit 1; }

  # Verify final status
  verify_cluster || { echo -e "${RED}Cluster verification failed${NC}"; exit 1; }
}

# Run the main function
main